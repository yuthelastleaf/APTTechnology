{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuthelastleaf/APTTechnology/blob/main/ToonCrafter_jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af351a94-df55-403a-bb60-6d2e6e9db71c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'ToonCrafter' already exists and is not an empty directory.\n",
            "/content/ToonCrafter\n",
            "aria2 is already the newest version (1.36.0-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "6345a4|\u001b[1;32mOK\u001b[0m  |   238MiB/s|/content/ToonCrafter/checkpoints/tooncrafter_512_interp_v1/model.ckpt\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (6.0.3)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.3.0)\n",
            "Collecting torchmetrics>0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.15.0)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.24.0+cu126)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (2025.11.3)\n",
            "Collecting ftfy (from open_clip_torch)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.7.0)\n",
            "Requirement already satisfied: timm>=1.0.17 in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (1.0.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.5.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics>0.7.0->pytorch_lightning) (2.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->open_clip_torch) (0.2.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (1.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->open_clip_torch) (11.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.11.12)\n",
            "Downloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading open_clip_torch-3.2.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, ftfy, torchmetrics, pytorch_lightning, open_clip_torch\n",
            "Successfully installed ftfy-6.3.1 lightning-utilities-0.15.2 open_clip_torch-3.2.0 pytorch_lightning-2.6.0 torchmetrics-1.8.2\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from decord) (2.0.2)\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (0.6.0)\n",
            "Collecting einops==0.3.0 (from -r requirements.txt (line 2))\n",
            "  Using cached einops-0.3.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.37.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Collecting omegaconf==2.1.1 (from -r requirements.txt (line 5))\n",
            "  Using cached omegaconf-2.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.12.0.88)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (11.3.0)\n",
            "Collecting pytorch_lightning==1.9.3 (from -r requirements.txt (line 9))\n",
            "  Using cached pytorch_lightning-1.9.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (6.0.3)\n",
            "Collecting setuptools==65.6.3 (from -r requirements.txt (line 11))\n",
            "  Downloading setuptools-65.6.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.0.0 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0, 2.9.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m正在启动高性能版 ToonCrafter...\n",
            "no module 'xformers'. Processing without...\n",
            "no module 'xformers'. Processing without...\n",
            "AE working on z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ToonCrafter/gradio_app.py\", line 79, in <module>\n",
            "    dynamicrafter_iface = dynamicrafter_demo(result_dir)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/gradio_app.py\", line 29, in dynamicrafter_demo\n",
            "    image2video = Image2Video(result_dir, resolution=resolution)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/scripts/gradio/i2v_test_application.py\", line 28, in __init__\n",
            "    model = instantiate_from_config(model_config)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/utils/utils.py\", line 34, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict()))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/lvdm/models/ddpm3d.py\", line 1043, in __init__\n",
            "    super().__init__(*args, **kwargs)\n",
            "  File \"/content/ToonCrafter/lvdm/models/ddpm3d.py\", line 531, in __init__\n",
            "    self.instantiate_cond_stage(cond_stage_config)\n",
            "  File \"/content/ToonCrafter/lvdm/models/ddpm3d.py\", line 590, in instantiate_cond_stage\n",
            "    model = instantiate_from_config(config)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/utils/utils.py\", line 34, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict()))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/utils/utils.py\", line 42, in get_obj_from_str\n",
            "    return getattr(importlib.import_module(module, package=None), cls)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/content/ToonCrafter/lvdm/modules/encoders/condition.py\", line 3, in <module>\n",
            "    import kornia\n",
            "ModuleNotFoundError: No module named 'kornia'\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/ToonCrafter\n",
        "%cd /content/ToonCrafter\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "# --- 1. 下载全精度原版模型 (High Quality) ---\n",
        "# 既然显存够用，我们直接下载原版 model.ckpt，不带 _fp16 后缀\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/ToonCrafter/resolve/main/model.ckpt -d /content/ToonCrafter/checkpoints/tooncrafter_512_interp_v1 -o model.ckpt\n",
        "# ----------------------------------------\n",
        "\n",
        "# --- 2. 【必须执行】修复环境依赖报错 ---\n",
        "# 这些修复是针对 Python 环境的，跟显卡没关系，必须保留\n",
        "!sed -i 's/numpy==1.24.2/numpy/g' requirements.txt\n",
        "!sed -i 's/decord==0.6.0/decord/g' requirements.txt\n",
        "!sed -i 's/imageio==2.9.0/imageio/g' requirements.txt\n",
        "!sed -i 's/PyYAML==6.0/PyYAML/g' requirements.txt\n",
        "!sed -i 's/Pillow==9.5.0/Pillow/g' requirements.txt\n",
        "!sed -i 's/pandas==2.0.0/pandas/g' requirements.txt\n",
        "\n",
        "# --- 3. 手动安装关键库 ---\n",
        "# 提前安装 pytorch_lightning 避免安装脚本因为其他包失败而跳过它\n",
        "!pip install pytorch_lightning omegaconf open_clip_torch\n",
        "!pip install decord\n",
        "\n",
        "# --- 4. 安装剩余依赖 ---\n",
        "!pip install -r requirements.txt\n",
        "!pip install einops -U\n",
        "!pip uninstall keras -y\n",
        "\n",
        "# --- 5. 启动 ---\n",
        "print(\"正在启动高性能版 ToonCrafter...\")\n",
        "!python gradio_app.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. 确保在正确的目录下\n",
        "if os.path.exists(\"/content/ToonCrafter\"):\n",
        "    os.chdir(\"/content/ToonCrafter\")\n",
        "\n",
        "print(\"正在修复依赖环境...\")\n",
        "\n",
        "# 2. 安装导致崩溃的缺失库 (最关键的一步)\n",
        "os.system(\"pip install kornia\")\n",
        "os.system(\"pip install open_clip_torch\")\n",
        "\n",
        "# 3. 修改 requirements.txt 防止报错\n",
        "# 原因：你的环境是 Python 3.12，无法安装旧版 torch 2.0.0，\n",
        "# 所以我们需要删除这些行，强制使用环境自带的新版 PyTorch。\n",
        "req_file = \"requirements.txt\"\n",
        "if os.path.exists(req_file):\n",
        "    with open(req_file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    with open(req_file, \"w\") as f:\n",
        "        for line in lines:\n",
        "            # 过滤掉强制指定版本的 torch/torchvision，直接用系统自带的\n",
        "            if \"torch\" in line or \"torchvision\" in line:\n",
        "                continue\n",
        "            f.write(line)\n",
        "    print(\"requirements.txt 已修正 (移除旧版 torch 限制)\")\n",
        "\n",
        "# 4. 安装剩余的兼容依赖\n",
        "os.system(\"pip install -r requirements.txt\")\n",
        "\n",
        "# 1. 卸载导致报错的新版本\n",
        "os.system(\"pip uninstall -y open_clip_torch\")\n",
        "\n",
        "# 2. 安装兼容的旧版本 (2.20.0 是已知稳定的版本)\n",
        "os.system(\"pip install open_clip_torch==2.20.0\")\n",
        "\n",
        "print(\"✅ 环境修复完成！正在启动 ToonCrafter...\")\n",
        "\n",
        "# 5. 启动程序\n",
        "!python gradio_app.py"
      ],
      "metadata": {
        "id": "QQj3bZ6LuE5C",
        "outputId": "6be0ca78-bcad-4b4c-8948-c3b4db2c0251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在修复依赖环境...\n",
            "requirements.txt 已修正 (移除旧版 torch 限制)\n",
            "✅ 环境修复完成！正在启动 ToonCrafter...\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"正在修复 open_clip_torch 版本冲突...\")\n",
        "\n",
        "# 1. 卸载导致报错的新版本\n",
        "os.system(\"pip uninstall -y open_clip_torch\")\n",
        "\n",
        "# 2. 安装兼容的旧版本 (2.20.0 是已知稳定的版本)\n",
        "os.system(\"pip install open_clip_torch==2.20.0\")\n",
        "\n",
        "print(\"✅ 依赖库已降级。正在重启 ToonCrafter...\")\n",
        "\n",
        "# 3. 再次启动程序\n",
        "!python gradio_app.py"
      ],
      "metadata": {
        "id": "ffnvZYuf0YNf",
        "outputId": "e28e25a0-3da2-4e54-f2e2-77ac1d981c3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在修复 open_clip_torch 版本冲突...\n",
            "✅ 依赖库已降级。正在重启 ToonCrafter...\n",
            "python3: can't open file '/content/gradio_app.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# 1. 定义损坏文件的路径\n",
        "ckpt_path = \"/content/ToonCrafter/checkpoints/tooncrafter_512_interp_v1/model.ckpt\"\n",
        "ckpt_dir = os.path.dirname(ckpt_path)\n",
        "\n",
        "print(f\"正在检查文件: {ckpt_path}\")\n",
        "\n",
        "# 2. 删除损坏的文件\n",
        "if os.path.exists(ckpt_path):\n",
        "    file_size = os.path.getsize(ckpt_path) / (1024 * 1024) # MB\n",
        "    print(f\"检测到旧文件大小: {file_size:.2f} MB\")\n",
        "    print(\"正在删除损坏的文件...\")\n",
        "    os.remove(ckpt_path)\n",
        "else:\n",
        "    print(\"文件不存在，准备下载...\")\n",
        "\n",
        "# 确保目录存在\n",
        "os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "# 3. 重新下载模型 (使用 HuggingFace 源，约 4.6GB)\n",
        "print(\"正在开始重新下载 model.ckpt，请耐心等待 (约 4.6GB)...\")\n",
        "# 使用 wget 下载，-O 指定输出文件名\n",
        "download_cmd = f\"wget -c https://huggingface.co/Doubiiu/ToonCrafter/resolve/main/model.ckpt -O {ckpt_path}\"\n",
        "os.system(download_cmd)\n",
        "\n",
        "# 4. 验证下载是否成功\n",
        "if os.path.exists(ckpt_path):\n",
        "    new_size = os.path.getsize(ckpt_path) / (1024 * 1024 * 1024) # GB\n",
        "    print(f\"下载完成！当前文件大小: {new_size:.2f} GB\")\n",
        "    if new_size < 1.0:\n",
        "        print(\"⚠️ 警告：文件似乎仍然过小，可能下载失败，请检查网络或重新运行。\")\n",
        "    else:\n",
        "        print(\"✅ 文件校验通过。\")\n",
        "\n",
        "        # 5. 再次尝试启动\n",
        "        print(\"正在重启 ToonCrafter...\")\n",
        "        os.system(\"python gradio_app.py\")\n",
        "else:\n",
        "    print(\"❌ 下载失败，未找到文件。\")"
      ],
      "metadata": {
        "id": "rrPhXysXu_GF",
        "outputId": "7976e585-9d1b-405f-fd60-3cfbe0f87474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "正在检查文件: /content/ToonCrafter/checkpoints/tooncrafter_512_interp_v1/model.ckpt\n",
            "检测到旧文件大小: 10015.96 MB\n",
            "正在删除损坏的文件...\n",
            "正在开始重新下载 model.ckpt，请耐心等待 (约 4.6GB)...\n",
            "下载完成！当前文件大小: 9.78 GB\n",
            "✅ 文件校验通过。\n",
            "正在重启 ToonCrafter...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}