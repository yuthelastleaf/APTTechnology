{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuthelastleaf/APTTechnology/blob/main/ToonCrafter_jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af351a94-df55-403a-bb60-6d2e6e9db71c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'ToonCrafter' already exists and is not an empty directory.\n",
            "/content/ToonCrafter\n",
            "aria2 is already the newest version (1.36.0-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "6345a4|\u001b[1;32mOK\u001b[0m  |   238MiB/s|/content/ToonCrafter/checkpoints/tooncrafter_512_interp_v1/model.ckpt\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (6.0.3)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.3.0)\n",
            "Collecting torchmetrics>0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.15.0)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.24.0+cu126)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (2025.11.3)\n",
            "Collecting ftfy (from open_clip_torch)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.7.0)\n",
            "Requirement already satisfied: timm>=1.0.17 in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (1.0.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.5.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics>0.7.0->pytorch_lightning) (2.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->open_clip_torch) (0.2.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (1.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->open_clip_torch) (11.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.11.12)\n",
            "Downloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading open_clip_torch-3.2.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, ftfy, torchmetrics, pytorch_lightning, open_clip_torch\n",
            "Successfully installed ftfy-6.3.1 lightning-utilities-0.15.2 open_clip_torch-3.2.0 pytorch_lightning-2.6.0 torchmetrics-1.8.2\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from decord) (2.0.2)\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (0.6.0)\n",
            "Collecting einops==0.3.0 (from -r requirements.txt (line 2))\n",
            "  Using cached einops-0.3.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.37.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Collecting omegaconf==2.1.1 (from -r requirements.txt (line 5))\n",
            "  Using cached omegaconf-2.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.12.0.88)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (11.3.0)\n",
            "Collecting pytorch_lightning==1.9.3 (from -r requirements.txt (line 9))\n",
            "  Using cached pytorch_lightning-1.9.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (6.0.3)\n",
            "Collecting setuptools==65.6.3 (from -r requirements.txt (line 11))\n",
            "  Downloading setuptools-65.6.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.0.0 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0, 2.9.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m正在启动高性能版 ToonCrafter...\n",
            "no module 'xformers'. Processing without...\n",
            "no module 'xformers'. Processing without...\n",
            "AE working on z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ToonCrafter/gradio_app.py\", line 79, in <module>\n",
            "    dynamicrafter_iface = dynamicrafter_demo(result_dir)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/gradio_app.py\", line 29, in dynamicrafter_demo\n",
            "    image2video = Image2Video(result_dir, resolution=resolution)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/scripts/gradio/i2v_test_application.py\", line 28, in __init__\n",
            "    model = instantiate_from_config(model_config)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/utils/utils.py\", line 34, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict()))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/lvdm/models/ddpm3d.py\", line 1043, in __init__\n",
            "    super().__init__(*args, **kwargs)\n",
            "  File \"/content/ToonCrafter/lvdm/models/ddpm3d.py\", line 531, in __init__\n",
            "    self.instantiate_cond_stage(cond_stage_config)\n",
            "  File \"/content/ToonCrafter/lvdm/models/ddpm3d.py\", line 590, in instantiate_cond_stage\n",
            "    model = instantiate_from_config(config)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/utils/utils.py\", line 34, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict()))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/utils/utils.py\", line 42, in get_obj_from_str\n",
            "    return getattr(importlib.import_module(module, package=None), cls)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/content/ToonCrafter/lvdm/modules/encoders/condition.py\", line 3, in <module>\n",
            "    import kornia\n",
            "ModuleNotFoundError: No module named 'kornia'\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/ToonCrafter\n",
        "%cd /content/ToonCrafter\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "# --- 1. 下载全精度原版模型 (High Quality) ---\n",
        "# 既然显存够用，我们直接下载原版 model.ckpt，不带 _fp16 后缀\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/ToonCrafter/resolve/main/model.ckpt -d /content/ToonCrafter/checkpoints/tooncrafter_512_interp_v1 -o model.ckpt\n",
        "# ----------------------------------------\n",
        "\n",
        "# --- 2. 【必须执行】修复环境依赖报错 ---\n",
        "# 这些修复是针对 Python 环境的，跟显卡没关系，必须保留\n",
        "!sed -i 's/numpy==1.24.2/numpy/g' requirements.txt\n",
        "!sed -i 's/decord==0.6.0/decord/g' requirements.txt\n",
        "!sed -i 's/imageio==2.9.0/imageio/g' requirements.txt\n",
        "!sed -i 's/PyYAML==6.0/PyYAML/g' requirements.txt\n",
        "!sed -i 's/Pillow==9.5.0/Pillow/g' requirements.txt\n",
        "!sed -i 's/pandas==2.0.0/pandas/g' requirements.txt\n",
        "\n",
        "# --- 3. 手动安装关键库 ---\n",
        "# 提前安装 pytorch_lightning 避免安装脚本因为其他包失败而跳过它\n",
        "!pip install pytorch_lightning omegaconf open_clip_torch\n",
        "!pip install decord\n",
        "\n",
        "# --- 4. 安装剩余依赖 ---\n",
        "!pip install -r requirements.txt\n",
        "!pip install einops -U\n",
        "!pip uninstall keras -y\n",
        "\n",
        "# --- 5. 启动 ---\n",
        "print(\"正在启动高性能版 ToonCrafter...\")\n",
        "!python gradio_app.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. 确保在正确的目录下\n",
        "if os.path.exists(\"/content/ToonCrafter\"):\n",
        "    os.chdir(\"/content/ToonCrafter\")\n",
        "\n",
        "print(\"正在修复依赖环境...\")\n",
        "\n",
        "# 2. 安装核心依赖 (加上 xformers 防止代码报错)\n",
        "os.system(\"pip install xformers\")  # 【新增】解决 NameError 关键\n",
        "os.system(\"pip install kornia\")\n",
        "\n",
        "# 3. 修改 requirements.txt 防止 PyTorch 版本冲突\n",
        "req_file = \"requirements.txt\"\n",
        "if os.path.exists(req_file):\n",
        "    with open(req_file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    with open(req_file, \"w\") as f:\n",
        "        for line in lines:\n",
        "            # 过滤掉强制指定版本的 torch/torchvision，直接用系统自带的\n",
        "            if \"torch\" in line or \"torchvision\" in line:\n",
        "                continue\n",
        "            f.write(line)\n",
        "    print(\"requirements.txt 已修正 (移除旧版 torch 限制)\")\n",
        "\n",
        "# 4. 安装剩余的兼容依赖\n",
        "os.system(\"pip install -r requirements.txt\")\n",
        "\n",
        "# 5. 解决 OpenCLIP 版本报错 (降级到 2.20.0)\n",
        "print(\"正在调整 open_clip_torch 版本...\")\n",
        "os.system(\"pip uninstall -y open_clip_torch\")\n",
        "os.system(\"pip install open_clip_torch==2.20.0\")\n",
        "\n",
        "# 6. 【保险措施】自动修补代码文件\n",
        "# 防止即使安装了 xformers 依然因为路径问题报错\n",
        "target_file = \"/content/ToonCrafter/lvdm/models/autoencoder_dualref.py\"\n",
        "if os.path.exists(target_file):\n",
        "    with open(target_file, \"r\") as f:\n",
        "        code = f.read()\n",
        "\n",
        "    # 简单的字符串替换，给 xformers 调用加上 try-except 保护\n",
        "    if \"xformers.ops.memory_efficient_attention\" in code and \"try:\" not in code:\n",
        "        print(\"正在为 autoencoder_dualref.py 应用防崩溃补丁...\")\n",
        "        patch = \"\"\"\n",
        "        try:\n",
        "            import xformers.ops\n",
        "            out = xformers.ops.memory_efficient_attention(q, k, v)\n",
        "        except (ImportError, NameError, AttributeError):\n",
        "            import torch.nn.functional as F\n",
        "            q_in = q.transpose(1, 2)\n",
        "            k_in = k.transpose(1, 2)\n",
        "            v_in = v.transpose(1, 2)\n",
        "            out = F.scaled_dot_product_attention(q_in, k_in, v_in)\n",
        "            out = out.transpose(1, 2)\n",
        "        \"\"\"\n",
        "        new_code = code.replace(\"out = xformers.ops.memory_efficient_attention(q, k, v)\", patch)\n",
        "        with open(target_file, \"w\") as f:\n",
        "            f.write(new_code)\n",
        "\n",
        "print(\"✅ 环境修复完成！正在启动 ToonCrafter...\")\n",
        "\n",
        "# 7. 启动程序\n",
        "!python gradio_app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQj3bZ6LuE5C",
        "outputId": "b039c7fa-e0b5-4f31-80da-576697fc2391"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在修复依赖环境...\n",
            "requirements.txt 已修正 (移除旧版 torch 限制)\n",
            "✅ 环境修复完成！正在启动 ToonCrafter...\n",
            "no module 'xformers'. Processing without...\n",
            "no module 'xformers'. Processing without...\n",
            "AE working on z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "2025-12-24 05:27:13.067800: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-24 05:27:13.085222: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766554033.103806   16237 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766554033.110299   16237 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766554033.127713   16237 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766554033.127741   16237 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766554033.127744   16237 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766554033.127756   16237 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-24 05:27:13.132703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "open_clip_pytorch_model.bin: 100% 3.94G/3.94G [00:12<00:00, 312MB/s]\n",
            "checkpoints/tooncrafter_512_interp_v1/model.ckpt\n",
            ">>> model checkpoint loaded.\n",
            "/content/ToonCrafter/gradio_app.py:30: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(analytics_enabled=False, css=css) as dynamicrafter_iface:\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://9660f8020abc3fbf04.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Seed set to 123\n",
            "start:  2025-12-24 05:28:37\n",
            "/content/ToonCrafter/scripts/gradio/i2v_test_application.py:59: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast():\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\", line 759, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2191, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1698, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/to_thread.py\", line 61, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2525, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 986, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 915, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/scripts/gradio/i2v_test_application.py\", line 100, in get_image\n",
            "    batch_samples = batch_ddim_sampling(model, cond, noise_shape, n_samples=1, ddim_steps=steps, ddim_eta=eta, cfg_scale=cfg_scale, hs=hs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/scripts/evaluation/funcs.py\", line 78, in batch_ddim_sampling\n",
            "    batch_images = model.decode_first_stage(samples, **additional_decode_kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/lvdm/models/ddpm3d.py\", line 683, in decode_first_stage\n",
            "    return self.decode_core(z, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/lvdm/models/ddpm3d.py\", line 671, in decode_core\n",
            "    out = self.first_stage_model.decode(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/lvdm/models/autoencoder.py\", line 115, in decode\n",
            "    dec = self.decoder(z, **kwargs)  ##change for SVD decoder by adding **kwargs\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/lvdm/models/autoencoder_dualref.py\", line 501, in forward\n",
            "    h = self.mid.attn_1(h, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/lvdm/models/autoencoder_dualref.py\", line 204, in forward\n",
            "    h_ = self.attention(h_)\n",
            "         ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ToonCrafter/lvdm/models/autoencoder_dualref.py\", line 190, in attention\n",
            "    out = xformers.ops.memory_efficient_attention(\n",
            "          ^^^^^^^^\n",
            "NameError: name 'xformers' is not defined\n",
            "Keyboard interruption in main thread... closing server.Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3043, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ToonCrafter/gradio_app.py\", line 81, in <module>\n",
            "    dynamicrafter_iface.launch(max_threads=1, share=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2950, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3045, in block_thread\n",
            "    print(\"Keyboard interruption in main thread... closing server.\")\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/wandb/sdk/lib/console_capture.py\", line 178, in write_with_callbacks\n",
            "    callbacks_list = stack.enter_context(_enter_callbacks(callbacks))\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 526, in enter_context\n",
            "    result = _enter(cm)\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 137, in __enter__\n",
            "    return next(self.gen)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/wandb/sdk/lib/console_capture.py\", line 224, in _enter_callbacks\n",
            "    callbacks_list = list(callbacks.values())\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://9660f8020abc3fbf04.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"正在修复 open_clip_torch 版本冲突...\")\n",
        "\n",
        "# 1. 卸载导致报错的新版本\n",
        "os.system(\"pip uninstall -y open_clip_torch\")\n",
        "\n",
        "# 2. 安装兼容的旧版本 (2.20.0 是已知稳定的版本)\n",
        "os.system(\"pip install open_clip_torch==2.20.0\")\n",
        "\n",
        "print(\"✅ 依赖库已降级。正在重启 ToonCrafter...\")\n",
        "\n",
        "# 3. 再次启动程序\n",
        "!python gradio_app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffnvZYuf0YNf",
        "outputId": "e28e25a0-3da2-4e54-f2e2-77ac1d981c3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在修复 open_clip_torch 版本冲突...\n",
            "✅ 依赖库已降级。正在重启 ToonCrafter...\n",
            "python3: can't open file '/content/gradio_app.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# 1. 定义损坏文件的路径\n",
        "ckpt_path = \"/content/ToonCrafter/checkpoints/tooncrafter_512_interp_v1/model.ckpt\"\n",
        "ckpt_dir = os.path.dirname(ckpt_path)\n",
        "\n",
        "print(f\"正在检查文件: {ckpt_path}\")\n",
        "\n",
        "# 2. 删除损坏的文件\n",
        "if os.path.exists(ckpt_path):\n",
        "    file_size = os.path.getsize(ckpt_path) / (1024 * 1024) # MB\n",
        "    print(f\"检测到旧文件大小: {file_size:.2f} MB\")\n",
        "    print(\"正在删除损坏的文件...\")\n",
        "    os.remove(ckpt_path)\n",
        "else:\n",
        "    print(\"文件不存在，准备下载...\")\n",
        "\n",
        "# 确保目录存在\n",
        "os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "# 3. 重新下载模型 (使用 HuggingFace 源，约 4.6GB)\n",
        "print(\"正在开始重新下载 model.ckpt，请耐心等待 (约 4.6GB)...\")\n",
        "# 使用 wget 下载，-O 指定输出文件名\n",
        "download_cmd = f\"wget -c https://huggingface.co/Doubiiu/ToonCrafter/resolve/main/model.ckpt -O {ckpt_path}\"\n",
        "os.system(download_cmd)\n",
        "\n",
        "# 4. 验证下载是否成功\n",
        "if os.path.exists(ckpt_path):\n",
        "    new_size = os.path.getsize(ckpt_path) / (1024 * 1024 * 1024) # GB\n",
        "    print(f\"下载完成！当前文件大小: {new_size:.2f} GB\")\n",
        "    if new_size < 1.0:\n",
        "        print(\"⚠️ 警告：文件似乎仍然过小，可能下载失败，请检查网络或重新运行。\")\n",
        "    else:\n",
        "        print(\"✅ 文件校验通过。\")\n",
        "\n",
        "        # 5. 再次尝试启动\n",
        "        print(\"正在重启 ToonCrafter...\")\n",
        "        os.system(\"python gradio_app.py\")\n",
        "else:\n",
        "    print(\"❌ 下载失败，未找到文件。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrPhXysXu_GF",
        "outputId": "7976e585-9d1b-405f-fd60-3cfbe0f87474"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "正在检查文件: /content/ToonCrafter/checkpoints/tooncrafter_512_interp_v1/model.ckpt\n",
            "检测到旧文件大小: 10015.96 MB\n",
            "正在删除损坏的文件...\n",
            "正在开始重新下载 model.ckpt，请耐心等待 (约 4.6GB)...\n",
            "下载完成！当前文件大小: 9.78 GB\n",
            "✅ 文件校验通过。\n",
            "正在重启 ToonCrafter...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}